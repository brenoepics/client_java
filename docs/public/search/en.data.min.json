[{"id":0,"href":"/config/config/","title":"Config","parent":"Config","content":" Location of the Properties File Metrics Properties Exemplar Properties Exporter Properties Exporter Filter Properties Exporter HTTPServer Properties Exporter OpenTelemetry Properties The Prometheus metrics library provides multiple options how to override configuration at runtime:\nProperties file System properties Future releases will add more options, like configuration via environment variables.\nExample:\nio.prometheus.exporter.httpServer.port = 9401 The property above changes the port for the HTTPServer exporter to 9401.\nProperties file: Add the line above to the properties file. System properties: Use the command line parameter -Dio.prometheus.exporter.httpServer.port=9401 when starting your application. Location of the Properties File The properties file is searched in the following locations:\n/prometheus.properties in the classpath. This is for bundling a properties file with your application. System property -Dprometheus.config=/path/to/prometheus.properties. Environment variable PROMETHEUS_CONFIG=/path/to/prometheus.properties. Metrics Properties Name Javadoc Note io.prometheus.metrics.exemplarsEnabled Counter.Builder.withExemplars() (1) (2) io.prometheus.metrics.histogramNativeOnly Histogram.Builder.nativeOnly() (2) io.prometheus.metrics.histogramClassicOnly Histogram.Builder.classicOnly() (2) io.prometheus.metrics.histogramClassicUpperBounds Histogram.Builder.classicUpperBounds() (3) io.prometheus.metrics.histogramNativeInitialSchema Histogram.Builder.nativeInitialSchema() io.prometheus.metrics.histogramNativeMinZeroThreshold Histogram.Builder.nativeMinZeroThreshold() io.prometheus.metrics.histogramNativeMaxZeroThreshold Histogram.Builder.nativeMaxZeroThreshold() io.prometheus.metrics.histogramNativeMaxNumberOfBuckets Histogram.Builder.nativeMaxNumberOfBuckets() io.prometheus.metrics.histogramNativeResetDurationSeconds Histogram.Builder.nativeResetDuration() io.prometheus.metrics.summaryQuantiles Summary.Builder.quantile(double) (4) io.prometheus.metrics.summaryQuantileErrors Summary.Builder.quantile(double, double) (5) io.prometheus.metrics.summaryMaxAgeSeconds Summary.Builder.maxAgeSeconds() io.prometheus.metrics.summaryNumberOfAgeBuckets Summary.Builder.numberOfAgeBuckets() Notes\n(1) withExemplars() and withoutExemplars() are available for all metric types, not just for counters\n(2) Boolean value. Format: property=true or property=false.\n(3) Comma-separated list. Example: .005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10.\n(4) Comma-separated list. Example: 0.5, 0.95, 0.99.\n(5) Comma-separated list. If specified, the list must have the same length as io.prometheus.metrics.summaryQuantiles. Example: 0.01, 0.005, 0.005.\nThere\u0026rsquo;s one special feature about metric properties: You can set a property for one specific metric only by specifying the metric name. Example: Let\u0026rsquo;s say you have a histogram named latency_seconds.\nio.prometheus.metrics.histogramClassicUpperBounds = 0.2, 0.4, 0.8, 1.0 The line above sets histogram buckets for all histograms. However:\nio.prometheus.metrics.latency_seconds.histogramClassicUpperBounds = 0.2, 0.4, 0.8, 1.0 The line above sets histogram buckets only for the histogram named latency_seconds.\nThis works for all Metrics properties.\nExemplar Properties Name Javadoc Note io.prometheus.exemplars.minRetentionPeriodSeconds ExemplarsProperties.getMinRetentionPeriodSeconds() io.prometheus.exemplars.maxRetentionPeriodSeconds ExemplarsProperties.getMaxRetentionPeriodSeconds() io.prometheus.exemplars.sampleIntervalMilliseconds ExemplarsProperties.getSampleIntervalMilliseconds() Exporter Properties Name Javadoc Note io.prometheus.exporter.includeCreatedTimestamps ExporterProperties.getExemplarsOnAllMetricTypes() (1) io.prometheus.exporter.exemplarsOnAllMetricTypes ExporterProperties.getIncludeCreatedTimestamps() (1) (1) Boolean value, true or false. Default see Javadoc.\nExporter Filter Properties Name Javadoc Note io.prometheus.exporter.filter.metricNameMustBeEqualTo ExporterFilterProperties.getAllowedMetricNames() (1) io.prometheus.exporter.filter.metricNameMustNotBeEqualTo ExporterFilterProperties.getExcludedMetricNames() (2) io.prometheus.exporter.filter.metricNameMustStartWith ExporterFilterProperties.getAllowedMetricNamePrefixes() (3) io.prometheus.exporter.filter.metricNameMustNotStartWith ExporterFilterProperties.getExcludedMetricNamePrefixes() (4) (1) Comma sparated list of allowed metric names. Only these metrics will be exposed. (2) Comma sparated list of excluded metric names. These metrics will not be exposed. (3) Comma sparated list of prefixes. Only metrics starting with these prefixes will be exposed. (4) Comma sparated list of prefixes. Metrics starting with these prefixes will not be exposed.\nExporter HTTPServer Properties Name Javadoc Note io.prometheus.exporter.httpServer.port HTTPServer.Builder.port() Exporter OpenTelemetry Properties Name Javadoc Note io.prometheus.exporter.opentelemetry.protocol OpenTelemetryExporter.Builder.protocol() (1) io.prometheus.exporter.opentelemetry.endpoint OpenTelemetryExporter.Builder.endpoint() io.prometheus.exporter.opentelemetry.headers OpenTelemetryExporter.Builder.headers() (2) io.prometheus.exporter.opentelemetry.intervalSeconds OpenTelemetryExporter.Builder.intervalSeconds() io.prometheus.exporter.opentelemetry.timeoutSeconds OpenTelemetryExporter.Builder.timeoutSeconds() io.prometheus.exporter.opentelemetry.serviceName OpenTelemetryExporter.Builder.serviceName() io.prometheus.exporter.opentelemetry.serviceNamespace OpenTelemetryExporter.Builder.serviceNamespace() io.prometheus.exporter.opentelemetry.serviceInstanceId OpenTelemetryExporter.Builder.serviceInstanceId() io.prometheus.exporter.opentelemetry.serviceVersion OpenTelemetryExporter.Builder.serviceVersion() io.prometheus.exporter.opentelemetry.resourceAttributes OpenTelemetryExporter.Builder.resourceAttributes() (3) (1) Protocol can be grpc or http/protobuf.\n(2) Format: key1=value1,key2=value2\n(3) Format: key1=value1,key2=value2\nMany of these attributes can alternatively be configured via OpenTelemetry environment variables, like OTEL_EXPORTER_OTLP_ENDPOINT. The Prometheus metrics library has support for OpenTelemetry environment variables. See Javadoc for details.\n","description":"Location of the Properties File Metrics Properties Exemplar Properties Exporter Properties Exporter Filter Properties Exporter HTTPServer Properties Exporter OpenTelemetry Properties The Prometheus metrics library provides multiple options how to override configuration at runtime:\nProperties file System properties Future releases will add more options, like configuration via environment variables.\nExample:\nio.prometheus.exporter.httpServer.port = 9401 The property above changes the port for the HTTPServer exporter to 9401.\nProperties file: Add the line above to the properties file."},{"id":1,"href":"/exporters/formats/","title":"Formats","parent":"Exporters","content":"All exporters the following exposition formats:\nOpenMetrics text format Prometheus text format Prometheus protobuf format Moreover, gzip encoding is supported for each of these formats.\nScraping with a Prometheus server The Prometheus server sends an Accept header to specify which format is requested. By default, the Prometheus server will scrape OpenMetrics text format with gzip encoding. If the Prometheus server is started with --enable-feature=native-histograms, it will scrape Prometheus protobuf format instead.\nViewing with a Web Browser If you view the /metrics endpoint with your Web browser you will see Prometheus text format. For quick debugging of the other formats, exporters provide a debug URL parameter:\n/metrics?debug=openmetrics: View OpenMetrics text format. /metrics?debug=text: View Prometheus text format. /metrics?debug=prometheus-protobuf: View a text representation of the Prometheus protobuf format. ","description":"All exporters the following exposition formats:\nOpenMetrics text format Prometheus text format Prometheus protobuf format Moreover, gzip encoding is supported for each of these formats.\nScraping with a Prometheus server The Prometheus server sends an Accept header to specify which format is requested. By default, the Prometheus server will scrape OpenMetrics text format with gzip encoding. If the Prometheus server is started with --enable-feature=native-histograms, it will scrape Prometheus protobuf format instead."},{"id":2,"href":"/getting-started/","title":"Getting Started","parent":"client_java","content":"","description":""},{"id":3,"href":"/instrumentation/jvm/","title":"JVM","parent":"Instrumentation","content":"The JVM instrumentation module provides a variety of out-of-the-box JVM and process metrics. To use it, add the following dependency:\nGradle implementation \u0026#39;io.prometheus:prometheus-metrics-instrumentation-jvm:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-instrumentation-jvm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Now, you can register the JVM metrics as follows:\nJvmMetrics.builder().register(); The line above will initialize all JVM metrics and register them with the default registry. If you want to register the metrics with a custom PrometheusRegistry, you can pass the registry as parameter to the register() call.\nThe sections below describe the individual classes providing JVM metrics. If you don\u0026rsquo;t want to register all JVM metrics, you can register each of these classes individually rather than using JvmMetrics.\nJVM Buffer Pool Metrics JVM buffer pool metrics are provided by the JvmBufferPoolMetrics class. The data is coming from the BufferPoolMXBean. Example metrics:\n# HELP jvm_buffer_pool_capacity_bytes Bytes capacity of a given JVM buffer pool.\r# TYPE jvm_buffer_pool_capacity_bytes gauge\rjvm_buffer_pool_capacity_bytes{pool=\u0026#34;direct\u0026#34;} 8192.0\rjvm_buffer_pool_capacity_bytes{pool=\u0026#34;mapped\u0026#34;} 0.0\r# HELP jvm_buffer_pool_used_buffers Used buffers of a given JVM buffer pool.\r# TYPE jvm_buffer_pool_used_buffers gauge\rjvm_buffer_pool_used_buffers{pool=\u0026#34;direct\u0026#34;} 1.0\rjvm_buffer_pool_used_buffers{pool=\u0026#34;mapped\u0026#34;} 0.0\r# HELP jvm_buffer_pool_used_bytes Used bytes of a given JVM buffer pool.\r# TYPE jvm_buffer_pool_used_bytes gauge\rjvm_buffer_pool_used_bytes{pool=\u0026#34;direct\u0026#34;} 8192.0\rjvm_buffer_pool_used_bytes{pool=\u0026#34;mapped\u0026#34;} 0.0 JVM Class Loading Metrics JVM class loading metrics are provided by the JvmClassLoadingMetrics class. The data is coming from the ClassLoadingMXBean. Example metrics:\n# HELP jvm_classes_currently_loaded The number of classes that are currently loaded in the JVM\r# TYPE jvm_classes_currently_loaded gauge\rjvm_classes_currently_loaded 1109.0\r# HELP jvm_classes_loaded_total The total number of classes that have been loaded since the JVM has started execution\r# TYPE jvm_classes_loaded_total counter\rjvm_classes_loaded_total 1109.0\r# HELP jvm_classes_unloaded_total The total number of classes that have been unloaded since the JVM has started execution\r# TYPE jvm_classes_unloaded_total counter\rjvm_classes_unloaded_total 0.0 JVM Compilation Metrics JVM compilation metrics are provided by the JvmCompilationMetrics class. The data is coming from the CompilationMXBean. Example metrics:\n# HELP jvm_compilation_time_seconds_total The total time in seconds taken for HotSpot class compilation\r# TYPE jvm_compilation_time_seconds_total counter\rjvm_compilation_time_seconds_total 0.152 JVM Garbage Collector Metrics JVM garbage collector metrics are provided by the JvmGarbageCollectorMetric class. The data is coming from the GarbageCollectorMXBean. Example metrics:\n# HELP jvm_gc_collection_seconds Time spent in a given JVM garbage collector in seconds.\r# TYPE jvm_gc_collection_seconds summary\rjvm_gc_collection_seconds_count{gc=\u0026#34;PS MarkSweep\u0026#34;} 0\rjvm_gc_collection_seconds_sum{gc=\u0026#34;PS MarkSweep\u0026#34;} 0.0\rjvm_gc_collection_seconds_count{gc=\u0026#34;PS Scavenge\u0026#34;} 0\rjvm_gc_collection_seconds_sum{gc=\u0026#34;PS Scavenge\u0026#34;} 0.0 JVM Memory Metrics JVM memory metrics are provided by the JvmMemoryMetrics class. The data is coming from the MemoryMXBean and the MemoryPoolMXBean. Example metrics:\n# HELP jvm_memory_committed_bytes Committed (bytes) of a given JVM memory area.\r# TYPE jvm_memory_committed_bytes gauge\rjvm_memory_committed_bytes{area=\u0026#34;heap\u0026#34;} 4.98597888E8\rjvm_memory_committed_bytes{area=\u0026#34;nonheap\u0026#34;} 1.1993088E7\r# HELP jvm_memory_init_bytes Initial bytes of a given JVM memory area.\r# TYPE jvm_memory_init_bytes gauge\rjvm_memory_init_bytes{area=\u0026#34;heap\u0026#34;} 5.20093696E8\rjvm_memory_init_bytes{area=\u0026#34;nonheap\u0026#34;} 2555904.0\r# HELP jvm_memory_max_bytes Max (bytes) of a given JVM memory area.\r# TYPE jvm_memory_max_bytes gauge\rjvm_memory_max_bytes{area=\u0026#34;heap\u0026#34;} 7.38983936E9\rjvm_memory_max_bytes{area=\u0026#34;nonheap\u0026#34;} -1.0\r# HELP jvm_memory_objects_pending_finalization The number of objects waiting in the finalizer queue.\r# TYPE jvm_memory_objects_pending_finalization gauge\rjvm_memory_objects_pending_finalization 0.0\r# HELP jvm_memory_pool_collection_committed_bytes Committed after last collection bytes of a given JVM memory pool.\r# TYPE jvm_memory_pool_collection_committed_bytes gauge\rjvm_memory_pool_collection_committed_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 1.30023424E8\rjvm_memory_pool_collection_committed_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 3.47078656E8\rjvm_memory_pool_collection_committed_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 2.1495808E7\r# HELP jvm_memory_pool_collection_init_bytes Initial after last collection bytes of a given JVM memory pool.\r# TYPE jvm_memory_pool_collection_init_bytes gauge\rjvm_memory_pool_collection_init_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 1.30023424E8\rjvm_memory_pool_collection_init_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 3.47078656E8\rjvm_memory_pool_collection_init_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 2.1495808E7\r# HELP jvm_memory_pool_collection_max_bytes Max bytes after last collection of a given JVM memory pool.\r# TYPE jvm_memory_pool_collection_max_bytes gauge\rjvm_memory_pool_collection_max_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 2.727870464E9\rjvm_memory_pool_collection_max_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 5.542248448E9\rjvm_memory_pool_collection_max_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 2.1495808E7\r# HELP jvm_memory_pool_collection_used_bytes Used bytes after last collection of a given JVM memory pool.\r# TYPE jvm_memory_pool_collection_used_bytes gauge\rjvm_memory_pool_collection_used_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 0.0\rjvm_memory_pool_collection_used_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 1249696.0\rjvm_memory_pool_collection_used_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 0.0\r# HELP jvm_memory_pool_committed_bytes Committed bytes of a given JVM memory pool.\r# TYPE jvm_memory_pool_committed_bytes gauge\rjvm_memory_pool_committed_bytes{pool=\u0026#34;Code Cache\u0026#34;} 4128768.0\rjvm_memory_pool_committed_bytes{pool=\u0026#34;Compressed Class Space\u0026#34;} 917504.0\rjvm_memory_pool_committed_bytes{pool=\u0026#34;Metaspace\u0026#34;} 6946816.0\rjvm_memory_pool_committed_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 1.30023424E8\rjvm_memory_pool_committed_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 3.47078656E8\rjvm_memory_pool_committed_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 2.1495808E7\r# HELP jvm_memory_pool_init_bytes Initial bytes of a given JVM memory pool.\r# TYPE jvm_memory_pool_init_bytes gauge\rjvm_memory_pool_init_bytes{pool=\u0026#34;Code Cache\u0026#34;} 2555904.0\rjvm_memory_pool_init_bytes{pool=\u0026#34;Compressed Class Space\u0026#34;} 0.0\rjvm_memory_pool_init_bytes{pool=\u0026#34;Metaspace\u0026#34;} 0.0\rjvm_memory_pool_init_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 1.30023424E8\rjvm_memory_pool_init_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 3.47078656E8\rjvm_memory_pool_init_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 2.1495808E7\r# HELP jvm_memory_pool_max_bytes Max bytes of a given JVM memory pool.\r# TYPE jvm_memory_pool_max_bytes gauge\rjvm_memory_pool_max_bytes{pool=\u0026#34;Code Cache\u0026#34;} 2.5165824E8\rjvm_memory_pool_max_bytes{pool=\u0026#34;Compressed Class Space\u0026#34;} 1.073741824E9\rjvm_memory_pool_max_bytes{pool=\u0026#34;Metaspace\u0026#34;} -1.0\rjvm_memory_pool_max_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 2.727870464E9\rjvm_memory_pool_max_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 5.542248448E9\rjvm_memory_pool_max_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 2.1495808E7\r# HELP jvm_memory_pool_used_bytes Used bytes of a given JVM memory pool.\r# TYPE jvm_memory_pool_used_bytes gauge\rjvm_memory_pool_used_bytes{pool=\u0026#34;Code Cache\u0026#34;} 4065472.0\rjvm_memory_pool_used_bytes{pool=\u0026#34;Compressed Class Space\u0026#34;} 766680.0\rjvm_memory_pool_used_bytes{pool=\u0026#34;Metaspace\u0026#34;} 6659432.0\rjvm_memory_pool_used_bytes{pool=\u0026#34;PS Eden Space\u0026#34;} 7801536.0\rjvm_memory_pool_used_bytes{pool=\u0026#34;PS Old Gen\u0026#34;} 1249696.0\rjvm_memory_pool_used_bytes{pool=\u0026#34;PS Survivor Space\u0026#34;} 0.0\r# HELP jvm_memory_used_bytes Used bytes of a given JVM memory area.\r# TYPE jvm_memory_used_bytes gauge\rjvm_memory_used_bytes{area=\u0026#34;heap\u0026#34;} 9051232.0\rjvm_memory_used_bytes{area=\u0026#34;nonheap\u0026#34;} 1.1490688E7 JVM Memory Pool Allocation Metrics JVM memory pool allocation metrics are provided by the JvmMemoryPoolAllocationMetrics class. The data is obtained by adding a NotificationListener to the GarbageCollectorMXBean. Example metrics:\n# HELP jvm_memory_pool_allocated_bytes_total Total bytes allocated in a given JVM memory pool. Only updated after GC, not continuously.\r# TYPE jvm_memory_pool_allocated_bytes_total counter\rjvm_memory_pool_allocated_bytes_total{pool=\u0026#34;Code Cache\u0026#34;} 4336448.0\rjvm_memory_pool_allocated_bytes_total{pool=\u0026#34;Compressed Class Space\u0026#34;} 875016.0\rjvm_memory_pool_allocated_bytes_total{pool=\u0026#34;Metaspace\u0026#34;} 7480456.0\rjvm_memory_pool_allocated_bytes_total{pool=\u0026#34;PS Eden Space\u0026#34;} 1.79232824E8\rjvm_memory_pool_allocated_bytes_total{pool=\u0026#34;PS Old Gen\u0026#34;} 1428888.0\rjvm_memory_pool_allocated_bytes_total{pool=\u0026#34;PS Survivor Space\u0026#34;} 4115280.0 JVM Runtime Info Metric The JVM runtime info metric is provided by the JvmRuntimeInfoMetric class. The data is obtained via system properties and will not change throughout the lifetime of the application. Example metric:\n# TYPE jvm_runtime info\r# HELP jvm_runtime JVM runtime info\rjvm_runtime_info{runtime=\u0026#34;OpenJDK Runtime Environment\u0026#34;,vendor=\u0026#34;Oracle Corporation\u0026#34;,version=\u0026#34;1.8.0_382-b05\u0026#34;} 1 JVM Thread Metrics JVM thread metrics are provided by the JvmThreadsMetrics class. The data is coming from the ThreadMXBean. Example metrics:\n# HELP jvm_threads_current Current thread count of a JVM\r# TYPE jvm_threads_current gauge\rjvm_threads_current 10.0\r# HELP jvm_threads_daemon Daemon thread count of a JVM\r# TYPE jvm_threads_daemon gauge\rjvm_threads_daemon 8.0\r# HELP jvm_threads_deadlocked Cycles of JVM-threads that are in deadlock waiting to acquire object monitors or ownable synchronizers\r# TYPE jvm_threads_deadlocked gauge\rjvm_threads_deadlocked 0.0\r# HELP jvm_threads_deadlocked_monitor Cycles of JVM-threads that are in deadlock waiting to acquire object monitors\r# TYPE jvm_threads_deadlocked_monitor gauge\rjvm_threads_deadlocked_monitor 0.0\r# HELP jvm_threads_peak Peak thread count of a JVM\r# TYPE jvm_threads_peak gauge\rjvm_threads_peak 10.0\r# HELP jvm_threads_started_total Started thread count of a JVM\r# TYPE jvm_threads_started_total counter\rjvm_threads_started_total 10.0\r# HELP jvm_threads_state Current count of threads by state\r# TYPE jvm_threads_state gauge\rjvm_threads_state{state=\u0026#34;BLOCKED\u0026#34;} 0.0\rjvm_threads_state{state=\u0026#34;NEW\u0026#34;} 0.0\rjvm_threads_state{state=\u0026#34;RUNNABLE\u0026#34;} 5.0\rjvm_threads_state{state=\u0026#34;TERMINATED\u0026#34;} 0.0\rjvm_threads_state{state=\u0026#34;TIMED_WAITING\u0026#34;} 2.0\rjvm_threads_state{state=\u0026#34;UNKNOWN\u0026#34;} 0.0\rjvm_threads_state{state=\u0026#34;WAITING\u0026#34;} 3.0 Process Metrics Process metrics are provided by the ProcessMetrics class. The data is coming from the OperatingSystemMXBean, the RuntimeMXBean, and from the /proc/self/status file on Linux. The metrics with prefix process_ are not specific to Java, but should be provided by every Prometheus client library, see Process Metrics in the Prometheus writing client libraries documentation. Example metrics:\n# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.\r# TYPE process_cpu_seconds_total counter\rprocess_cpu_seconds_total 1.63\r# HELP process_max_fds Maximum number of open file descriptors.\r# TYPE process_max_fds gauge\rprocess_max_fds 524288.0\r# HELP process_open_fds Number of open file descriptors.\r# TYPE process_open_fds gauge\rprocess_open_fds 28.0\r# HELP process_resident_memory_bytes Resident memory size in bytes.\r# TYPE process_resident_memory_bytes gauge\rprocess_resident_memory_bytes 7.8577664E7\r# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.\r# TYPE process_start_time_seconds gauge\rprocess_start_time_seconds 1.693829439767E9\r# HELP process_virtual_memory_bytes Virtual memory size in bytes.\r# TYPE process_virtual_memory_bytes gauge\rprocess_virtual_memory_bytes 1.2683624448E10 ","description":"The JVM instrumentation module provides a variety of out-of-the-box JVM and process metrics. To use it, add the following dependency:\nGradle implementation \u0026#39;io.prometheus:prometheus-metrics-instrumentation-jvm:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-instrumentation-jvm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Now, you can register the JVM metrics as follows:\nJvmMetrics.builder().register(); The line above will initialize all JVM metrics and register them with the default registry. If you want to register the metrics with a custom PrometheusRegistry, you can pass the registry as parameter to the register() call."},{"id":4,"href":"/internals/model/","title":"Model","parent":"Internals","content":"The illustration below shows the internal architecture of the Prometheus Java client library.\nprometheus-metrics-core This is the user facing metrics library, implementing the core metric types, like Counter, Gauge Histogram, and so on.\nAll metric types implement the Collector interface, i.e. they provide a collect() method to produce snapshots.\nprometheus-metrics-model The model is an internal library, implementing read-only immutable snapshots. These snapshots are returned by the Collector.collect() method.\nThere is no need for users to use prometheus-metrics-model directly. Users should use the API provided by prometheus-metrics-core, which includes the core metrics as well as callback metrics.\nHowever, maintainers of 3rd party metrics libraries might want to use prometheus-metrics-model if they want to add Prometheus exposition formats to their metrics library.\nexporters and exposition formats The prometheus-metrics-exposition-formats module converts snapshots to Prometheus exposition formats, like text format, OpenMetrics text format, or Prometheus protobuf format.\nThe exporters like prometheus-metrics-exporter-httpserver or prometheus-metrics-exporter-servlet-jakarta use this to convert snapshots into the right format depending on the Accept header in the scrape request.\n","description":"The illustration below shows the internal architecture of the Prometheus Java client library.\nprometheus-metrics-core This is the user facing metrics library, implementing the core metric types, like Counter, Gauge Histogram, and so on.\nAll metric types implement the Collector interface, i.e. they provide a collect() method to produce snapshots.\nprometheus-metrics-model The model is an internal library, implementing read-only immutable snapshots. These snapshots are returned by the Collector.collect() method.\nThere is no need for users to use prometheus-metrics-model directly."},{"id":5,"href":"/otel/otlp/","title":"OTLP","parent":"OpenTelemetry","content":"The Prometheus Java client library allows you to push metrics to an OpenTelemetry endpoint using the OTLP protocol.\nTo implement this, you need to include prometheus-metrics-exporter as a dependency\nGradle implementation \u0026#39;io.prometheus:prometheus-metrics-exporter-opentelemetry:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-exporter-opentelemetry\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Initialize the OpenTelemetryExporter in your Java code:\nOpenTelemetryExporter.builder() // optional: call configuration methods here .buildAndStart(); By default, the OpenTelemetryExporter will push metrics every 60 seconds to localhost:4317 using grpc protocol. You can configure this in code using the OpenTelemetryExporter.Builder, or at runtime via io.prometheus.exporter.opentelemetry.* properties.\nIn addition to the Prometheus Java client configuration, the exporter also recognizes standard OpenTelemetry configuration. For example, you can set the OTEL_EXPORTER_OTLP_METRICS_ENDPOINT environment variable to configure the endpoint. The Javadoc for OpenTelemetryExporter.Builder shows which settings have corresponding OTel configuration. The intended use case is that if you attach the OpenTelemetry Java agent for tracing, and use the Prometheus Java client for metrics, it is sufficient to configure the OTel agent because the Prometheus library will pick up the same configuration.\nThe examples/example-exporter-opentelemetry folder has a docker compose with a complete end-to-end example, including a Java app, the OTel collector, and a Prometheus server.\n","description":"The Prometheus Java client library allows you to push metrics to an OpenTelemetry endpoint using the OTLP protocol.\nTo implement this, you need to include prometheus-metrics-exporter as a dependency\nGradle implementation \u0026#39;io.prometheus:prometheus-metrics-exporter-opentelemetry:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-exporter-opentelemetry\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Initialize the OpenTelemetryExporter in your Java code:\nOpenTelemetryExporter.builder() // optional: call configuration methods here .buildAndStart(); By default, the OpenTelemetryExporter will push metrics every 60 seconds to localhost:4317 using grpc protocol. You can configure this in code using the OpenTelemetryExporter."},{"id":6,"href":"/getting-started/quickstart/","title":"Quickstart","parent":"Getting Started","content":"This tutorial shows the quickest way to get started with the Prometheus Java metrics library.\nDependencies We use the following dependencies:\nprometheus-metrics-core is the actual metrics library. prometheus-metrics-instrumentation-jvm provides out-of-the-box JVM metrics. prometheus-metrics-exporter-httpserver is a standalone HTTP server for exposing Prometheus metrics. Gradle implementation \u0026#39;io.prometheus:prometheus-metrics-core:1.0.0\u0026#39;\rimplementation \u0026#39;io.prometheus:prometheus-metrics-instrumentation-jvm:1.0.0\u0026#39;\rimplementation \u0026#39;io.prometheus:prometheus-metrics-exporter-httpserver:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-instrumentation-jvm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-exporter-httpserver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; There are alternative exporters as well, for example if you are using a Servlet container like Tomcat or Undertow you might want to use prometheus-exporter-servlet-jakarta rather than a standalone HTTP server.\nExample Application import io.prometheus.metrics.core.metrics.Counter; import io.prometheus.metrics.exporter.httpserver.HTTPServer; import io.prometheus.metrics.instrumentation.jvm.JvmMetrics; import java.io.IOException; public class App { public static void main(String[] args) throws InterruptedException, IOException { JvmMetrics.builder().register(); // initialize the out-of-the-box JVM metrics Counter counter = Counter.builder() .name(\u0026#34;my_count_total\u0026#34;) .help(\u0026#34;example counter\u0026#34;) .labelNames(\u0026#34;status\u0026#34;) .register(); counter.labelValues(\u0026#34;ok\u0026#34;).inc(); counter.labelValues(\u0026#34;ok\u0026#34;).inc(); counter.labelValues(\u0026#34;error\u0026#34;).inc(); HTTPServer server = HTTPServer.builder() .port(9400) .buildAndStart(); System.out.println(\u0026#34;HTTPServer listening on port http://localhost:\u0026#34; + server.getPort() + \u0026#34;/metrics\u0026#34;); Thread.currentThread().join(); // sleep forever } } Result Run the application and view http://localhost:9400/metrics with your browser to see the raw metrics. You should see the my_count_total metric as shown below plus the jvm_ and process_ metrics coming from JvmMetrics.\n# HELP my_count_total example counter\r# TYPE my_count_total counter\rmy_count_total{status=\u0026#34;error\u0026#34;} 1.0\rmy_count_total{status=\u0026#34;ok\u0026#34;} 2.0 Prometheus Configuration To scrape the metrics with a Prometheus server, download the latest Prometheus server release, and configure the prometheus.yml file as follows:\nglobal: scrape_interval: 10s # short interval for manual testing scrape_configs: - job_name: \u0026#34;java-example\u0026#34; static_configs: - targets: [\u0026#34;localhost:9400\u0026#34;] ","description":"This tutorial shows the quickest way to get started with the Prometheus Java metrics library.\nDependencies We use the following dependencies:\nprometheus-metrics-core is the actual metrics library. prometheus-metrics-instrumentation-jvm provides out-of-the-box JVM metrics. prometheus-metrics-exporter-httpserver is a standalone HTTP server for exposing Prometheus metrics. Gradle implementation \u0026#39;io.prometheus:prometheus-metrics-core:1.0.0\u0026#39;\rimplementation \u0026#39;io.prometheus:prometheus-metrics-instrumentation-jvm:1.0.0\u0026#39;\rimplementation \u0026#39;io.prometheus:prometheus-metrics-exporter-httpserver:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-instrumentation-jvm\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-exporter-httpserver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; There are alternative exporters as well, for example if you are using a Servlet container like Tomcat or Undertow you might want to use prometheus-exporter-servlet-jakarta rather than a standalone HTTP server."},{"id":7,"href":"/migration/simpleclient/","title":"Simpleclient","parent":"Compatibility","content":"The Prometheus Java client library 1.0.0 is a complete rewrite of the underlying data model, and is not backwards compatible with releases 0.16.0 and older for a variety of reasons:\nThe old data model was based on OpenMetrics. Native histograms don\u0026rsquo;t fit with the OpenMetrics model because they don\u0026rsquo;t follow the \u0026ldquo;every sample has exactly one double value\u0026rdquo; paradigm. It was a lot cleaner to implement a dedicated prometheus-metrics-model than trying to fit native histograms into the existing OpenMetrics-based model. Version 0.16.0 and older has multiple Maven modules sharing the same Java package name. This is not supported by the Java module system. To support users of Java modules, we renamed all packages and made sure no package is reused across multiple Maven modules. Migration using the Simpleclient Bridge Good news: Users of version 0.16.0 and older do not need to refactor all their instrumentation code to get started with 1.0.0.\nWe provide a migration module for bridging the old simpleclient CollectorRegistry to the new PromethesuRegistry.\nTo use the bridge, add the following dependency:\nGradle implementation \u0026#39;io.prometheus:prometheus-metrics-simpleclient-bridge:1.0.0\u0026#39; Maven \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.prometheus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;prometheus-metrics-simpleclient-bridge\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Then add the following to your code:\nSimpleclientCollector.builder().register(); This will make all metrics registered with simpleclient\u0026rsquo;s CollectorRegistry.defaultRegistry available in the new PrometheusRegistry.defaultRegistry.\nIf you are using custom registries, you can specify them like this:\nCollectorRegistry simpleclientRegistry = ...; PrometheusRegistry prometheusRegistry = ...; SimpleclientCollector.builder() .collectorRegistry(simpleclientRegistry) .register(prometheusRegistry); Refactoring the Instrumentation Code If you decide to get rid of the old 0.16.0 dependencies and use 1.0.0 only, you need to refactor your code:\nDependencies:\nsimpleclient -\u0026gt; prometheus-metrics-core simpleclient_hotspot -\u0026gt; prometheus-metrics-instrumentation-jvm simpleclient_httpserver -\u0026gt; prometheus-metrics-exporter-httpserver simpleclient_servlet_jakarta -\u0026gt; prometheus-metrics-exporter-servlet-jakarta As long as you are using high-level metric API like Counter, Gauge, Histogram, and Summary converting code to the new API is relatively straightforward. You will need to adapt the package name and apply some minor changes like using builder() instead of build() or using labelValues() instead of labels().\nExample of the old 0.16.0 API:\nimport io.prometheus.client.Counter; Counter counter = Counter.build() .name(\u0026#34;test\u0026#34;) .help(\u0026#34;test counter\u0026#34;) .labelNames(\u0026#34;path\u0026#34;) .register(); counter.labels(\u0026#34;/hello-world\u0026#34;).inc(); Example of the new 1.0.0 API:\nimport io.prometheus.metrics.core.metrics.Counter; Counter counter = Counter.builder() .name(\u0026#34;test\u0026#34;) .help(\u0026#34;test counter\u0026#34;) .labelNames(\u0026#34;path\u0026#34;) .register(); counter.labelValues(\u0026#34;/hello-world\u0026#34;).inc(); Reasons why we changed the API: Changing the package names was a necessity because the previous package names were incompatible with the Java module system. However, renaming packages requires changing code anyway, so we decided to clean up some things. For example, the name builder() for a builder method is very common in the Java ecosystem, it\u0026rsquo;s used in Spring, Lombok, and so on. So naming the method builder() makes the Prometheus library more aligned with the broader Java ecosystem.\nIf you are using the low level Collector API directly, you should have a look at the new callback metric types, see /getting-started/callbacks/. Chances are good that the new callback metrics have an easier way to achieve what you need than the old 0.16.0 code.\n","description":"The Prometheus Java client library 1.0.0 is a complete rewrite of the underlying data model, and is not backwards compatible with releases 0.16.0 and older for a variety of reasons:\nThe old data model was based on OpenMetrics. Native histograms don\u0026rsquo;t fit with the OpenMetrics model because they don\u0026rsquo;t follow the \u0026ldquo;every sample has exactly one double value\u0026rdquo; paradigm. It was a lot cleaner to implement a dedicated prometheus-metrics-model than trying to fit native histograms into the existing OpenMetrics-based model."},{"id":8,"href":"/exporters/","title":"Exporters","parent":"client_java","content":"","description":""},{"id":9,"href":"/exporters/filter/","title":"Filter","parent":"Exporters","content":"All exporters support a name[] URL parameter for querying only specific metric names. Examples:\n/metrics?name[]=jvm_threads_current will query the metric named jvm_threads_current. /metrics?name[]=jvm_threads_current\u0026amp;name[]=jvm_threads_daemon will query two metrics, jvm_threads_current and jvm_threads_daemon. Add the following to the scape job configuration in prometheus.yml to make the Prometheus server send the name[] parameter:\nparams: name[]: - jvm_threads_current - jvm_threads_daemon ","description":"All exporters support a name[] URL parameter for querying only specific metric names. Examples:\n/metrics?name[]=jvm_threads_current will query the metric named jvm_threads_current. /metrics?name[]=jvm_threads_current\u0026amp;name[]=jvm_threads_daemon will query two metrics, jvm_threads_current and jvm_threads_daemon. Add the following to the scape job configuration in prometheus.yml to make the Prometheus server send the name[] parameter:\nparams: name[]: - jvm_threads_current - jvm_threads_daemon "},{"id":10,"href":"/getting-started/registry/","title":"Registry","parent":"Getting Started","content":"In order to expose metrics, you need to register them with a PrometheusRegistry. We are using a counter as an example here, but the register() method is the same for all metric types.\nRegistering a Metrics with the Default Registry Counter eventsTotal = Counter.builder() .name(\u0026#34;events_total\u0026#34;) .help(\u0026#34;Total number of events\u0026#34;) .register(); // \u0026lt;-- implicitly uses PrometheusRegistry.defaultRegistry The register() call above builds the counter and registers it with the global static PrometheusRegistry.defaultRegistry. Using the default registry is recommended.\nRegistering a Metrics with a Custom Registry You can also register your metric with a custom registry:\nPrometheusRegistry myRegistry = new PrometheusRegistry(); Counter eventsTotal = Counter.builder() .name(\u0026#34;events_total\u0026#34;) .help(\u0026#34;Total number of events\u0026#34;) .register(myRegistry); Registering a Metric with Multiple Registries As an alternative to calling register() directly, you can build() metrics without registering them, and register them later:\n// create a counter that is not registered with any registry Counter eventsTotal = Counter.builder() .name(\u0026#34;events_total\u0026#34;) .help(\u0026#34;Total number of events\u0026#34;) .build(); // \u0026lt;-- this will create the metric but not register it // register the counter with the default registry PrometheusRegistry.defaultRegistry.register(eventsTotal); // register the counter with a custom registry. // This is ok, you can register a metric with multiple registries. PrometheusRegistry myRegistry = new PrometheusRegistry(); myRegistry.register(eventsTotal); Custom registries are useful if you want to maintain different scopes of metrics, like a debug registry with a lot of metrics, and a default registry with only a few metrics.\nIllegalArgumentException: Duplicate Metric Name in Registry While it is ok to register the same metric with multiple registries, it is illegal to register the same metric name multiple times with the same registry. The following code will throw an IllegalArgumentException:\nCounter eventsTotal1 = Counter.builder() .name(\u0026#34;events_total\u0026#34;) .help(\u0026#34;Total number of events\u0026#34;) .register(); Counter eventsTotal2 = Counter.builder() .name(\u0026#34;events_total\u0026#34;) .help(\u0026#34;Total number of events\u0026#34;) .register(); // \u0026lt;-- IllegalArgumentException, because a metric with that name is already registered Unregistering a Metric There is no automatic expiry of unused metrics (yet), once a metric is registered it will remain registered forever.\nHowever, you can programmatically unregistered an obsolete metric like this:\nPrometheusRegistry.defaultRegistry.unregister(eventsTotal); ","description":"In order to expose metrics, you need to register them with a PrometheusRegistry. We are using a counter as an example here, but the register() method is the same for all metric types.\nRegistering a Metrics with the Default Registry Counter eventsTotal = Counter.builder() .name(\u0026#34;events_total\u0026#34;) .help(\u0026#34;Total number of events\u0026#34;) .register(); // \u0026lt;-- implicitly uses PrometheusRegistry.defaultRegistry The register() call above builds the counter and registers it with the global static PrometheusRegistry.defaultRegistry. Using the default registry is recommended."},{"id":11,"href":"/otel/tracing/","title":"Tracing","parent":"OpenTelemetry","content":"OpenTelemetry’s vision statement says that telemetry should be loosely coupled, allowing end users to pick and choose from the pieces they want without having to bring in the rest of the project, too. In that spirit, you might choose to instrument your Java application with the Prometheus Java client library for metrics, and attach the OpenTelemetry Java agent to get distributed tracing.\nFirst, if you attach the OpenTelemetry Java agent you might want to turn off OTel\u0026rsquo;s built-in metrics, because otherwise you get metrics from both the Prometheus Java client library and the OpenTelemetry agent (technically it\u0026rsquo;s no problem to get both metrics, it\u0026rsquo;s just not a common use case).\n# This will tell the OpenTelemetry agent not to send metrics, just traces and logs. export OTEL_METRICS_EXPORTER=none Now, start your application with the OpenTelemetry Java agent attached for traces and logs.\njava -javaagent:path/to/opentelemetry-javaagent.jar -jar myapp.jar With the OpenTelemetry Java agent attached, the Prometheus client library will do a lot of magic under the hood.\nservice.name and service.instance.id are used in OpenTelemetry to uniquely identify a service instance. The Prometheus client library will automatically use the same service.name and service.instance.id as the agent when pushing metrics in OpenTelemetry format. That way the monitoring backend will see that the metrics and the traces are coming from the same instance. Exemplars are added automatically if a Prometheus metric is updated in the context of a distributed OpenTelemetry trace. If a Span is used as an Exemplar, the Span is marked with the Span attribute exemplar=\u0026quot;true\u0026quot;. This can be used in the OpenTelemetry\u0026rsquo;s sampling policy to make sure Exemplars are always sampled. Here\u0026rsquo;s more context on the exemplar=\u0026quot;true\u0026quot; Span attribute: Many users of tracing libraries don\u0026rsquo;t keep 100% of their trace data, because traces are very repetitive. It is very common to sample only 10% of traces and discard 90%. However, this can be an issue with Exemplars: In 90% of the cases Exemplars would point to a trace that has been thrown away.\nTo solve this, the Prometheus Java client library annotates each Span that has been used as an Exemplar with the exemplar=\u0026quot;true\u0026quot; Span attribute.\nThe sampling policy in the OpenTelemetry collector can be configured to keep traces with this attribute. There\u0026rsquo;s no risk that this results in a significant increase in trace data, because new Exemplars are only selected every minRetentionPeriodSeconds seconds.\nHere\u0026rsquo;s an example of how to configure OpenTelemetry\u0026rsquo;s tail sampling processor to sample all Spans marked with exemplar=\u0026quot;true\u0026quot;, and then discard 90% of the traces:\npolicies: [ { name: keep-exemplars, type: string_attribute, string_attribute: { key: \u0026#34;exemplar\u0026#34;, values: [ \u0026#34;true\u0026#34; ] } }, { name: keep-10-percent, type: probabilistic, probabilistic: { sampling_percentage: 10 } }, ] The examples/example-exemplar-tail-sampling/ directory has a complete end-to-end example, with a distributed Java application with two services, an OpenTelemetry collector, Prometheus, Tempo as a trace database, and Grafana dashboards. Use docker-compose as described in the example\u0026rsquo;s README to run the example and explore the results.\n","description":"OpenTelemetry’s vision statement says that telemetry should be loosely coupled, allowing end users to pick and choose from the pieces they want without having to bring in the rest of the project, too. In that spirit, you might choose to instrument your Java application with the Prometheus Java client library for metrics, and attach the OpenTelemetry Java agent to get distributed tracing.\nFirst, if you attach the OpenTelemetry Java agent you might want to turn off OTel\u0026rsquo;s built-in metrics, because otherwise you get metrics from both the Prometheus Java client library and the OpenTelemetry agent (technically it\u0026rsquo;s no problem to get both metrics, it\u0026rsquo;s just not a common use case)."},{"id":12,"href":"/exporters/httpserver/","title":"HTTPServer","parent":"Exporters","content":"The HTTPServer is a standalone server for exposing a metric endpoint. A minimal example application for HTTPServer can be found in the examples directory.\nHTTPServer server = HTTPServer.builder() .port(9400) .buildAndStart(); By default, HTTPServer binds to any IP address, you can change this with hostname() or inetAddress().\nHTTPServer is configured with three endpoints:\n/metrics for Prometheus scraping. /-/healthy for simple health checks. / the default handler is a static HTML page. The default handler can be changed with defaultHandler().\nAuthentication and HTTPS authenticator() is for configuring authentication. httpsConfigurator() is for configuring HTTPS. You can find an example of authentication and SSL in the jmx_exporter.\nProperties See config section (todo) on runtime configuration options.\nio.prometheus.exporter.httpServer.port: The port to bind to. ","description":"The HTTPServer is a standalone server for exposing a metric endpoint. A minimal example application for HTTPServer can be found in the examples directory.\nHTTPServer server = HTTPServer.builder() .port(9400) .buildAndStart(); By default, HTTPServer binds to any IP address, you can change this with hostname() or inetAddress().\nHTTPServer is configured with three endpoints:\n/metrics for Prometheus scraping. /-/healthy for simple health checks. / the default handler is a static HTML page. The default handler can be changed with defaultHandler()."},{"id":13,"href":"/instrumentation/","title":"Instrumentation","parent":"client_java","content":"","description":""},{"id":14,"href":"/getting-started/labels/","title":"Labels","parent":"Getting Started","content":"The following shows an example of a Prometheus metric in text format:\n# HELP payments_total total number of payments\r# TYPE payments_total counter\rpayments_total{status=\u0026#34;error\u0026#34;,type=\u0026#34;paypal\u0026#34;} 1.0\rpayments_total{status=\u0026#34;success\u0026#34;,type=\u0026#34;credit card\u0026#34;} 3.0\rpayments_total{status=\u0026#34;success\u0026#34;,type=\u0026#34;paypal\u0026#34;} 2.0 The example shows a counter metric named payments_total with two labels: status and type. Each individual data point (each line in text format) is identified by the unique combination of its metric name and its label name/value pairs.\nCreating a Metric with Labels Labels are supported for all metric types. We are using counters in this example, however the labelNames() and labelValues() methods are the same for other metric types.\nThe following code creates the counter above.\nCounter counter = Counter.builder() .name(\u0026#34;payments_total\u0026#34;) .help(\u0026#34;total number of payments\u0026#34;) .labelNames(\u0026#34;type\u0026#34;, \u0026#34;status\u0026#34;) .register(); counter.labelValues(\u0026#34;credit card\u0026#34;, \u0026#34;success\u0026#34;).inc(3.0); counter.labelValues(\u0026#34;paypal\u0026#34;, \u0026#34;success\u0026#34;).inc(2.0); counter.labelValues(\u0026#34;paypal\u0026#34;, \u0026#34;error\u0026#34;).inc(1.0); The label names have to be specified when the metric is created and cannot change. The label values are created on demand when values are observed.\nCreating a Metric without Labels Labels are optional. The following example shows a metric without labels:\nCounter counter = Counter.builder() .name(\u0026#34;payments_total\u0026#34;) .help(\u0026#34;total number of payments\u0026#34;) .register(); counter.inc(3.0); Cardinality Explosion Each combination of label names and values will result in a new data point, i.e. a new line in text format. Therefore, a good label should have only a small number of possible values. If you select labels with many possible values, like unique IDs or timestamps, you may end up with an enormous number of data points. This is called cardinality explosion.\nHere\u0026rsquo;s a bad example, don\u0026rsquo;t do this:\nCounter loginCount = Counter.builder() .name(\u0026#34;logins_total\u0026#34;) .help(\u0026#34;total number of logins\u0026#34;) .labelNames(\u0026#34;user_id\u0026#34;, \u0026#34;timestamp\u0026#34;) // not a good idea, this will result in too many data points .register(); String userId = UUID.randomUUID().toString(); String timestamp = Long.toString(System.currentTimeMillis()); loginCount.labelValues(userId, timestamp).inc(); Initializing Label Values If you register a metric without labels, it will show up immediately with initial value of zero.\nHowever, metrics with labels only show up after the label values are first used. In the example above\ncounter.labelValues(\u0026#34;paypal\u0026#34;, \u0026#34;error\u0026#34;).inc(); The data point\npayments_total{status=\u0026#34;error\u0026#34;,type=\u0026#34;paypal\u0026#34;} 1.0 will jump from non-existent to value 1.0. You will never see it with value 0.0.\nThis is usually not an issue. However, if you find this annoying and want to see all possible label values from the start, you can initialize label values with initLabelValues() like this:\nCounter counter = Counter.builder() .name(\u0026#34;payments_total\u0026#34;) .help(\u0026#34;total number of payments\u0026#34;) .labelNames(\u0026#34;type\u0026#34;, \u0026#34;status\u0026#34;) .register(); counter.initLabelValues(\u0026#34;credit card\u0026#34;, \u0026#34;success\u0026#34;); counter.initLabelValues(\u0026#34;credit card\u0026#34;, \u0026#34;error\u0026#34;); counter.initLabelValues(\u0026#34;paypal\u0026#34;, \u0026#34;success\u0026#34;); counter.initLabelValues(\u0026#34;paypal\u0026#34;, \u0026#34;error\u0026#34;); Now the four combinations will be visible from the start with initial value zero.\n# HELP payments_total total number of payments\r# TYPE payments_total counter\rpayments_total{status=\u0026#34;error\u0026#34;,type=\u0026#34;credit card\u0026#34;} 0.0\rpayments_total{status=\u0026#34;error\u0026#34;,type=\u0026#34;paypal\u0026#34;} 0.0\rpayments_total{status=\u0026#34;success\u0026#34;,type=\u0026#34;credit card\u0026#34;} 0.0\rpayments_total{status=\u0026#34;success\u0026#34;,type=\u0026#34;paypal\u0026#34;} 0.0 Expiring Unused Label Values There is no automatic expiry of unused label values (yet). Once a set of label values is used, it will remain there forever.\nHowever, you can programmatically remove label values like this:\ncounter.remove(\u0026#34;paypal\u0026#34;, \u0026#34;error\u0026#34;); counter.remove(\u0026#34;paypal\u0026#34;, \u0026#34;success\u0026#34;); Const Labels If you have labels values that never change, you can specify them in the builder as constLabels():\nCounter counter = Counter.builder() .name(\u0026#34;payments_total\u0026#34;) .help(\u0026#34;total number of payments\u0026#34;) .constLabels(Labels.of(\u0026#34;env\u0026#34;, \u0026#34;dev\u0026#34;)) .labelNames(\u0026#34;type\u0026#34;, \u0026#34;status\u0026#34;) .register(); However, most use cases for constLabels() are better covered by target labels set by the scraping Prometheus server, or by one specific metric (e.g. a build_info or a machine_role metric). See also target labels, not static scraped labels.\n","description":"The following shows an example of a Prometheus metric in text format:\n# HELP payments_total total number of payments\r# TYPE payments_total counter\rpayments_total{status=\u0026#34;error\u0026#34;,type=\u0026#34;paypal\u0026#34;} 1.0\rpayments_total{status=\u0026#34;success\u0026#34;,type=\u0026#34;credit card\u0026#34;} 3.0\rpayments_total{status=\u0026#34;success\u0026#34;,type=\u0026#34;paypal\u0026#34;} 2.0 The example shows a counter metric named payments_total with two labels: status and type. Each individual data point (each line in text format) is identified by the unique combination of its metric name and its label name/value pairs.\nCreating a Metric with Labels Labels are supported for all metric types."},{"id":15,"href":"/otel/names/","title":"Names","parent":"OpenTelemetry","content":"OpenTelemetry naming conventions are different from Prometheus naming conventions. The mapping from OpenTelemetry metric names to Prometheus metric names is well defined in OpenTelemetry\u0026rsquo;s Prometheus and OpenMetrics Compatibility spec, and the OpenTelemetryExporter implements that specification.\nThe goal is, if you set up a pipeline as illustrated below, you will see the same metric names in the Prometheus server as if you had exposed Prometheus metrics directly.\nThe main steps when converting OpenTelemetry metric names to Prometheus metric names are:\nReplace dots with underscores. If the metric has a unit, append the unit to the metric name, like _seconds. If the metric type has a suffix, append it, like _total for counters. Dots in Metric and Label Names OpenTelemetry defines not only a line protocol, but also semantic conventions, i.e. standardized metric and label names. For example, OpenTelemetry\u0026rsquo;s Semantic Conventions for HTTP Metrics say that if you instrument an HTTP server with OpenTelemetry, you must have a histogram named http.server.duration.\nMost names defined in semantic conventions use dots. In the Prometheus server, the dot is an illegal character (this might change in future versions of the Prometheus server).\nThe Prometheus Java client library allows dots, so that you can use metric names and label names as defined in OpenTelemetry\u0026rsquo;s semantic conventions. The dots will automatically be replaced with underscores if you expose metrics in Prometheus format, but you will see the original names with dots if you push your metrics in OpenTelemetry format.\nThat way, you can use OTel-compliant metric and label names today when instrumenting your application with the Prometheus Java client, and you are prepared in case your monitoring backend adds features in the future that require OTel-compliant instrumentation.\n","description":"OpenTelemetry naming conventions are different from Prometheus naming conventions. The mapping from OpenTelemetry metric names to Prometheus metric names is well defined in OpenTelemetry\u0026rsquo;s Prometheus and OpenMetrics Compatibility spec, and the OpenTelemetryExporter implements that specification.\nThe goal is, if you set up a pipeline as illustrated below, you will see the same metric names in the Prometheus server as if you had exposed Prometheus metrics directly.\nThe main steps when converting OpenTelemetry metric names to Prometheus metric names are:"},{"id":16,"href":"/getting-started/metric-types/","title":"Metric Types","parent":"Getting Started","content":"The Prometheus Java metrics library implements the metric types defined in the OpenMetrics standard:\nCounter Gauge Histogram Summary Info StateSet GaugeHistogram and Unknown Counter Counter is the most common and useful metric type. Counters can only increase, but never decrease. In the Prometheus query language, the rate() function is often used for counters to calculate the average increase per second.\nCounter values do not need to be integers. In many cases counters represent a number of events (like the number of requests), and in that case the counter value is an integer. However, counters can also be used for something like \u0026ldquo;total time spent doing something\u0026rdquo; in which case the counter value is a floating point number. Here\u0026rsquo;s an example of a counter:\nCounter serviceTimeSeconds = Counter.builder() .name(\u0026#34;service_time_seconds_total\u0026#34;) .help(\u0026#34;total time spent serving requests\u0026#34;) .unit(Unit.SECONDS) .register(); serviceTimeSeconds.inc(Unit.millisToSeconds(200)); The resulting counter has the value 0.2. As SECONDS is the standard time unit in Prometheus, the Unit utility class has methods to convert other time units to seconds.\nAs defined in OpenMetrics, counter metric names must have the _total suffix. If you create a counter without the _total suffix the suffix will be appended automatically.\nGauge Gauges are current measurements, such as the current temperature in Celsius.\nGauge temperature = Gauge.builder() .name(\u0026#34;temperature_celsius\u0026#34;) .help(\u0026#34;current temperature\u0026#34;) .labelNames(\u0026#34;location\u0026#34;) .unit(Unit.CELSIUS) .register(); temperature.labelValues(\u0026#34;Berlin\u0026#34;).set(22.3); Histogram Histograms are for observing distributions, like latency distributions for HTTP services or the distribution of request sizes. Unlike with counters and gauges, each histogram data point has a complex data structure representing different aspects of the distribution:\nCount: The total number of observations. Sum: The sum of all observed values, e.g. the total time spent serving requests. Buckets: The histogram buckets representing the distribution. Prometheus supports two flavors of histograms:\nClassic histograms: Bucket boundaries are explicitly defined when the histogram is created. Native histograms (exponential histograms): Infinitely many virtual buckets. By default, histograms maintain both flavors. Which one is used depends on the scrape request from the Prometheus server.\nBy default, the Prometheus server will scrape metrics in OpenMetrics format and get the classic histogram flavor. If the Prometheus server is started with --enable-feature=native-histograms, it will request metrics in Prometheus protobuf format and ingest the native histogram. If the Prometheus server is started with --enable-feature=native-histogram and the scrape config has the option scrape_classic_histograms: true, it will request metrics in Prometheus protobuf format and ingest both, the classic and the native flavor. This is great for migrating from classic histograms to native histograms. See examples/example-native-histogram for an example.\nHistogram duration = Histogram.builder() .name(\u0026#34;http_request_duration_seconds\u0026#34;) .help(\u0026#34;HTTP request service time in seconds\u0026#34;) .unit(Unit.SECONDS) .labelNames(\u0026#34;method\u0026#34;, \u0026#34;path\u0026#34;, \u0026#34;status_code\u0026#34;) .register(); long start = System.nanoTime(); // do something duration.labelValues(\u0026#34;GET\u0026#34;, \u0026#34;/\u0026#34;, \u0026#34;200\u0026#34;).observe(Unit.nanosToSeconds(System.nanoTime() - start)); Histograms implement the TimerApi interface, which provides convenience methods for measuring durations.\nThe histogram builder provides a lot of configuration for fine-tuning the histogram behavior. In most cases you don\u0026rsquo;t need them, defaults are good. The following is an incomplete list showing the most important options:\nnativeOnly() / classicOnly(): Create a histogram with one representation only. classicBuckets(...): Set the classic bucket boundaries. Default buckets are .005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, and 10. The default bucket boundaries are designed for measuring request durations in seconds. nativeMaxNumberOfBuckets(): Upper limit for the number of native histogram buckets. Default is 160. When the maximum is reached, the native histogram automatically reduces resolution to stay below the limit. See Javadoc for Histogram.Builder for a complete list of options. Some options can be configured at runtime, see config.\nHistograms and summaries are both used for observing distributions. Therefore, the both implement the DistributionDataPoint interface. Using the DistributionDataPoint interface directly gives you the option to switch between histograms and summaries later with minimal code changes.\nExample of using the DistributionDataPoint interface for a histogram without labels:\nDistributionDataPoint eventDuration = Histogram.builder() .name(\u0026#34;event_duration_seconds\u0026#34;) .help(\u0026#34;event duration in seconds\u0026#34;) .unit(Unit.SECONDS) .register(); // The following still works perfectly fine if eventDuration // is backed by a summary rather than a histogram. eventDuration.observe(0.2); Example of using the DistributionDataPoint interface for a histogram with labels:\nHistogram eventDuration = Histogram.builder() .name(\u0026#34;event_duration_seconds\u0026#34;) .help(\u0026#34;event duration in seconds\u0026#34;) .labelNames(\u0026#34;status\u0026#34;) .unit(Unit.SECONDS) .register(); DistributionDataPoint successfulEvents = eventDuration.labelValues(\u0026#34;ok\u0026#34;); DistributionDataPoint erroneousEvents = eventDuration.labelValues(\u0026#34;error\u0026#34;); // Like in the example above, the following still works perfectly fine // if the successfulEvents and erroneousEvents are backed by a summary rather than a histogram. successfulEvents.observe(0.7); erroneousEvents.observe(0.2); Summary Like histograms, summaries are for observing distributions. Each summary data point has a count and a sum like a histogram data point. However, rather than histogram buckets summaries maintain quantiles.\nSummary requestLatency = Summary.builder() .name(\u0026#34;request_latency_seconds\u0026#34;) .help(\u0026#34;Request latency in seconds.\u0026#34;) .unit(Unit.SECONDS) .quantile(0.5, 0.01) .quantile(0.95, 0.005) .quantile(0.99, 0.005) .labelNames(\u0026#34;status\u0026#34;) .register(); requestLatency.labelValues(\u0026#34;ok\u0026#34;).observe(2.7); The example above creates a summary with the 50th percentile (median), the 95th percentile, and the 99th percentile. Quantiles are optional, you can create a summary without quantiles if all you need is the count and the sum.\nThe terms \u0026ldquo;percentile\u0026rdquo; and \u0026ldquo;quantile\u0026rdquo; mean the same thing. We use percentile when we express it as a number in [0, 100], and we use quantile when we express it as a number in [0.0, 1.0]. The second parameter to quantile() is the maximum acceptable error. The call .quantile(0.5, 0.01) means that the actual quantile is somewhere in [0.49, 0.51]. Higher precision means higher memory usage.\nThe 0.0 quantile (min value) and the 1.0 quantile (max value) are special cases because you can get the precise values (error 0.0) with almost no memory overhead.\nQuantile values are calculated based on a 5 minutes moving time window. The default time window can be changed with maxAgeSeconds() and numberOfAgeBuckets().\nSome options can be configured at runtime, see config.\nIn general you should prefer histograms over summaries. The Prometheus query language has a function histogram_quantile() for calculating quantiles from histograms. The advantage of query-time quantile calculation is that you can aggregate histograms before calculating the quantile. With summaries you must use the quantile with all its labels as it is.\nInfo Info metrics are used to expose textual information which should not change during process lifetime. The value of an Info metric is always 1.\nInfo info = Info.builder() .name(\u0026#34;jvm_runtime_info\u0026#34;) .help(\u0026#34;JVM runtime info\u0026#34;) .labelNames(\u0026#34;version\u0026#34;, \u0026#34;vendor\u0026#34;, \u0026#34;runtime\u0026#34;) .register(); String version = System.getProperty(\u0026#34;java.runtime.version\u0026#34;, \u0026#34;unknown\u0026#34;); String vendor = System.getProperty(\u0026#34;java.vm.vendor\u0026#34;, \u0026#34;unknown\u0026#34;); String runtime = System.getProperty(\u0026#34;java.runtime.name\u0026#34;, \u0026#34;unknown\u0026#34;); info.setLabelValues(version, vendor, runtime); The info above looks as follows in OpenMetrics text format:\n# TYPE jvm_runtime info\r# HELP jvm_runtime JVM runtime info\rjvm_runtime_info{runtime=\u0026#34;OpenJDK Runtime Environment\u0026#34;,vendor=\u0026#34;Oracle Corporation\u0026#34;,version=\u0026#34;1.8.0_382-b05\u0026#34;} 1 The example is taken from the prometheus-metrics-instrumentation-jvm module, so if you have JvmMetrics registered you should have a jvm_runtime_info metric out-of-the-box.\nAs defined in OpenMetrics, info metric names must have the _info suffix. If you create a counter without the _info suffix the suffix will be appended automatically.\nStateSet StateSet are a niche metric type in the OpenMetrics standard that is rarely used. The main use case is to signal which feature flags are enabled.\nStateSet stateSet = StateSet.builder() .name(\u0026#34;feature_flags\u0026#34;) .help(\u0026#34;Feature flags\u0026#34;) .labelNames(\u0026#34;env\u0026#34;) .states(\u0026#34;feature1\u0026#34;, \u0026#34;feature2\u0026#34;) .register(); stateSet.labelValues(\u0026#34;dev\u0026#34;).setFalse(\u0026#34;feature1\u0026#34;); stateSet.labelValues(\u0026#34;dev\u0026#34;).setTrue(\u0026#34;feature2\u0026#34;); The OpenMetrics text format looks like this:\n# TYPE feature_flags stateset\r# HELP feature_flags Feature flags\rfeature_flags{env=\u0026#34;dev\u0026#34;,feature_flags=\u0026#34;feature1\u0026#34;} 0\rfeature_flags{env=\u0026#34;dev\u0026#34;,feature_flags=\u0026#34;feature2\u0026#34;} 1 GaugeHistogram and Unknown These types are defined in the OpenMetrics standard but not implemented in the prometheus-metrics-core API. However, prometheus-metrics-model implements the underlying data model for these types. To use these types, you need to implement your own Collector where the collect() method returns an UnknownSnapshot or a HistogramSnapshot with .gaugeHistogram(true).\n","description":"The Prometheus Java metrics library implements the metric types defined in the OpenMetrics standard:\nCounter Gauge Histogram Summary Info StateSet GaugeHistogram and Unknown Counter Counter is the most common and useful metric type. Counters can only increase, but never decrease. In the Prometheus query language, the rate() function is often used for counters to calculate the average increase per second.\nCounter values do not need to be integers. In many cases counters represent a number of events (like the number of requests), and in that case the counter value is an integer."},{"id":17,"href":"/otel/","title":"OpenTelemetry","parent":"client_java","content":"","description":""},{"id":18,"href":"/exporters/servlet/","title":"Servlet","parent":"Exporters","content":"The PrometheusMetricsServlet is a Jakarta Servlet for exposing a metric endpoint.\nweb.xml The old-school way of configuring a servlet is in a web.xml file:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;https://jakarta.ee/xml/ns/jakartaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;https://jakarta.ee/xml/ns/jakartaee https://jakarta.ee/xml/ns/jakartaee/web-app_5_0.xsd\u0026#34; version=\u0026#34;5.0\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;prometheus-metrics\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;io.prometheus.metrics.exporter.servlet.jakarta.PrometheusMetricsServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;prometheus-metrics\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/metrics\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; Programmatic Today, most Servlet applications use an embedded Servlet container and configure Servlets programmatically rather than via web.xml. The API for that depends on the Servlet container. The examples directory has an example of an embedded Tomcat container with the PrometheusMetricsServlet configured.\nSpring You can use the PrometheusMetricsServlet in Spring applications. See our Spring doc.\n","description":"The PrometheusMetricsServlet is a Jakarta Servlet for exposing a metric endpoint.\nweb.xml The old-school way of configuring a servlet is in a web.xml file:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;https://jakarta.ee/xml/ns/jakartaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;https://jakarta.ee/xml/ns/jakartaee https://jakarta.ee/xml/ns/jakartaee/web-app_5_0.xsd\u0026#34; version=\u0026#34;5.0\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;prometheus-metrics\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;io.prometheus.metrics.exporter.servlet.jakarta.PrometheusMetricsServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;prometheus-metrics\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/metrics\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; Programmatic Today, most Servlet applications use an embedded Servlet container and configure Servlets programmatically rather than via web.xml. The API for that depends on the Servlet container. The examples directory has an example of an embedded Tomcat container with the PrometheusMetricsServlet configured."},{"id":19,"href":"/getting-started/callbacks/","title":"Callbacks","parent":"Getting Started","content":"The section on metric types showed how to use metrics that actively maintain their state.\nThis section shows how to create callback-based metrics, i.e. metrics that invoke a callback at scrape time to get the current values.\nFor example, let\u0026rsquo;s assume we have two instances of a Cache, a coldCache and a hotCache. The following implements a callback-based cache_size_bytes metric:\nCache coldCache = new Cache(); Cache hotCache = new Cache(); GaugeWithCallback.builder() .name(\u0026#34;cache_size_bytes\u0026#34;) .help(\u0026#34;Size of the cache in Bytes.\u0026#34;) .unit(Unit.BYTES) .labelNames(\u0026#34;state\u0026#34;) .callback(callback -\u0026gt; { callback.call(coldCache.sizeInBytes(), \u0026#34;cold\u0026#34;); callback.call(hotCache.sizeInBytes(), \u0026#34;hot\u0026#34;); }) .register(); The resulting text format looks like this:\n# TYPE cache_size_bytes gauge\r# UNIT cache_size_bytes bytes\r# HELP cache_size_bytes Size of the cache in Bytes.\rcache_size_bytes{state=\u0026#34;cold\u0026#34;} 78.0\rcache_size_bytes{state=\u0026#34;hot\u0026#34;} 83.0 Better examples of callback metrics can be found in the prometheus-metrics-instrumentation-jvm module.\nThe available callback metric types are:\nGaugeWithCallback for gauges. CounterWithCallback for counters. SummaryWithCallback for summaries. The API for gauges and counters is very similar. For summaries the callback has a few more parameters, because it accepts a count, a sum, and quantiles:\nSummaryWithCallback.builder() .name(\u0026#34;example_callback_summary\u0026#34;) .help(\u0026#34;help message.\u0026#34;) .labelNames(\u0026#34;status\u0026#34;) .callback(callback -\u0026gt; { callback.call(cache.getCount(), cache.getSum(), Quantiles.EMPTY, \u0026#34;ok\u0026#34;); }) .register(); ","description":"The section on metric types showed how to use metrics that actively maintain their state.\nThis section shows how to create callback-based metrics, i.e. metrics that invoke a callback at scrape time to get the current values.\nFor example, let\u0026rsquo;s assume we have two instances of a Cache, a coldCache and a hotCache. The following implements a callback-based cache_size_bytes metric:\nCache coldCache = new Cache(); Cache hotCache = new Cache(); GaugeWithCallback."},{"id":20,"href":"/config/","title":"Config","parent":"client_java","content":"","description":""},{"id":21,"href":"/exporters/spring/","title":"Spring","parent":"Exporters","content":" Alternative: Use Spring\u0026rsquo;s Built-in Metrics Library Spring Boot has a built-in metric library named Micrometer, which supports Prometheus exposition format and can be set up in three simple steps:\nAdd the org.springframework.boot:spring-boot-starter-actuator dependency. Add the io.micrometer:micrometer-registry-prometheus as a runtime dependency. Enable the Prometheus endpoint by adding the line management.endpoints.web.exposure.include=prometheus to application.properties. Note that Spring\u0026rsquo;s default Prometheus endpoint is /actuator/prometheus, not /metrics.\nIn most cases the built-in Spring metrics library will work for you and you don\u0026rsquo;t need the Prometheus Java library in Spring applications.\nUse the Prometheus Metrics Library in Spring However, you may have your reasons why you want to use the Prometheus metrics library in Spring anyway. Maybe you want full support for all Prometheus metric types, or you want to use the new Prometheus native histograms.\nThe easiest way to use the Prometheus metrics library in Spring is to configure the PrometheusMetricsServlet to expose metrics.\nDependencies:\nprometheus-metrics-core: The core metrics library. prometheus-metrics-exporter-servlet-jakarta: For providing the /metrics endpoint. prometheus-metrics-instrumentation-jvm: Optional - JVM metrics The following is the complete source code of a Spring Boot REST service using the Prometheus metrics library:\nimport io.prometheus.metrics.core.metrics.Counter; import io.prometheus.metrics.exporter.servlet.jakarta.PrometheusMetricsServlet; import io.prometheus.metrics.instrumentation.jvm.JvmMetrics; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.web.servlet.ServletRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @SpringBootApplication @RestController public class DemoApplication { private static final Counter requestCount = Counter.builder() .name(\u0026#34;requests_total\u0026#34;) .register(); public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); JvmMetrics.builder().register(); } @GetMapping(\u0026#34;/\u0026#34;) public String sayHello() throws InterruptedException { requestCount.inc(); return \u0026#34;Hello, World!\\n\u0026#34;; } @Bean public ServletRegistrationBean\u0026lt;PrometheusMetricsServlet\u0026gt; createPrometheusMetricsEndpoint() { return new ServletRegistrationBean\u0026lt;\u0026gt;(new PrometheusMetricsServlet(), \u0026#34;/metrics/*\u0026#34;); } } The important part are the last three lines: They configure the PrometheusMetricsServlet to expose metrics on /metrics:\n@Bean public ServletRegistrationBean\u0026lt;PrometheusMetricsServlet\u0026gt; createPrometheusMetricsEndpoint() { return new ServletRegistrationBean\u0026lt;\u0026gt;(new PrometheusMetricsServlet(), \u0026#34;/metrics/*\u0026#34;); } The example provides a Hello, world! endpoint on http://localhost:8080, and Prometheus metrics on http://localhost:8080/metrics.\n","description":"Alternative: Use Spring\u0026rsquo;s Built-in Metrics Library Spring Boot has a built-in metric library named Micrometer, which supports Prometheus exposition format and can be set up in three simple steps:\nAdd the org.springframework.boot:spring-boot-starter-actuator dependency. Add the io.micrometer:micrometer-registry-prometheus as a runtime dependency. Enable the Prometheus endpoint by adding the line management.endpoints.web.exposure.include=prometheus to application.properties. Note that Spring\u0026rsquo;s default Prometheus endpoint is /actuator/prometheus, not /metrics.\nIn most cases the built-in Spring metrics library will work for you and you don\u0026rsquo;t need the Prometheus Java library in Spring applications."},{"id":22,"href":"/migration/","title":"Compatibility","parent":"client_java","content":"","description":""},{"id":23,"href":"/getting-started/performance/","title":"Performance","parent":"Getting Started","content":"This section has tips on how to use the Prometheus Java client in high performance applications.\nSpecify Label Values Only Once For high performance applications, we recommend to specify label values only once, and then use the data point directly.\nThis applies to all metric types. Let\u0026rsquo;s use a counter as an example here:\nCounter requestCount = Counter.builder() .name(\u0026#34;requests_total\u0026#34;) .help(\u0026#34;total number of requests\u0026#34;) .labelNames(\u0026#34;path\u0026#34;, \u0026#34;status\u0026#34;) .register(); You could increment the counter above like this:\nrequestCount.labelValue(\u0026#34;/\u0026#34;, \u0026#34;200\u0026#34;).inc(); However, the line above does not only increment the counter, it also looks up the label values to find the right data point.\nIn high performance applications you can optimize this by looking up the data point only once:\nCounterDataPoint successfulCalls = requestCount.labelValues(\u0026#34;/\u0026#34;, \u0026#34;200\u0026#34;); Now, you can increment the data point directly, which is a highly optimized operation:\nsuccessfulCalls.inc(); Enable Only One Histogram Representation By default, histograms maintain two representations under the hood: The classic histogram representation with static buckets, and the native histogram representation with dynamic buckets.\nWhile this default provides the flexibility to scrape different representations at runtime, it comes at a cost, because maintaining multiple representations causes performance overhead.\nIn performance critical applications we recommend to use either the classic representation or the native representation, but not both.\nYou can either configure this in code for each histogram by calling classicOnly() or nativeOnly(), or you use the corresponding config options.\nOne way to do this is with system properties in the command line when you start your application\njava -Dio.prometheus.metrics.histogramClassicOnly=true my-app.jar or\njava -Dio.prometheus.metrics.histogramNativeOnly=true my-app.jar If you don\u0026rsquo;t want to add a command line parameter every time you start your application, you can add a prometheus.properties file to your classpath (put it in the src/main/resources/ directory so that it gets packed into your JAR file). The prometheus.properties file should have the following line:\nio.prometheus.metrics.histogramClassicOnly=true or\nio.prometheus.metrics.histogramNativeOnly=true Future releases will add more configuration options, like support for configuration via environment variableIO_PROMETHEUS_METRICS_HISTOGRAM_NATIVE_ONLY=true.\n","description":"This section has tips on how to use the Prometheus Java client in high performance applications.\nSpecify Label Values Only Once For high performance applications, we recommend to specify label values only once, and then use the data point directly.\nThis applies to all metric types. Let\u0026rsquo;s use a counter as an example here:\nCounter requestCount = Counter.builder() .name(\u0026#34;requests_total\u0026#34;) .help(\u0026#34;total number of requests\u0026#34;) .labelNames(\u0026#34;path\u0026#34;, \u0026#34;status\u0026#34;) .register(); You could increment the counter above like this:"},{"id":24,"href":"/internals/","title":"Internals","parent":"client_java","content":"","description":""},{"id":25,"href":"/getting-started/multi-target/","title":"Multi-Target Pattern","parent":"Getting Started","content":" This is for the upcoming release 1.1.0. To support multi-target pattern you can create a custom collector overriding the purposed internal method in ExtendedMultiCollector see SampleExtendedMultiCollector in io.prometheus.metrics.examples.httpserver\npublic class SampleExtendedMultiCollector extends ExtendedMultiCollector { public SampleExtendedMultiCollector() { super(); } @Override protected MetricSnapshots collectMetricSnapshots(PrometheusScrapeRequest scrapeRequest) { GaugeSnapshot.Builder gaugeBuilder = GaugeSnapshot.builder(); gaugeBuilder.name(\u0026#34;x_load\u0026#34;).help(\u0026#34;process load\u0026#34;); CounterSnapshot.Builder counterBuilder = CounterSnapshot.builder(); counterBuilder.name(PrometheusNaming.sanitizeMetricName(\u0026#34;x_calls_total\u0026#34;)).help(\u0026#34;invocations\u0026#34;); String[] targetNames = scrapeRequest.getParameterValues(\u0026#34;target\u0026#34;); String targetName; String[] procs = scrapeRequest.getParameterValues(\u0026#34;proc\u0026#34;); if (targetNames == null || targetNames.length == 0) { targetName = \u0026#34;defaultTarget\u0026#34;; procs = null; //ignore procs param } else { targetName = targetNames[0]; } Builder counterDataPointBuilder = CounterSnapshot.CounterDataPointSnapshot.builder(); io.prometheus.metrics.model.snapshots.GaugeSnapshot.GaugeDataPointSnapshot.Builder gaugeDataPointBuilder = GaugeSnapshot.GaugeDataPointSnapshot.builder(); Labels lbls = Labels.of(\u0026#34;target\u0026#34;, targetName); if (procs == null || procs.length == 0) { counterDataPointBuilder.labels(lbls.merge(Labels.of(\u0026#34;proc\u0026#34;, \u0026#34;defaultProc\u0026#34;))); gaugeDataPointBuilder.labels(lbls.merge(Labels.of(\u0026#34;proc\u0026#34;, \u0026#34;defaultProc\u0026#34;))); counterDataPointBuilder.value(70); gaugeDataPointBuilder.value(Math.random()); counterBuilder.dataPoint(counterDataPointBuilder.build()); gaugeBuilder.dataPoint(gaugeDataPointBuilder.build()); } else { for (int i = 0; i \u0026lt; procs.length; i++) { counterDataPointBuilder.labels(lbls.merge(Labels.of(\u0026#34;proc\u0026#34;, procs[i]))); gaugeDataPointBuilder.labels(lbls.merge(Labels.of(\u0026#34;proc\u0026#34;, procs[i]))); counterDataPointBuilder.value(Math.random()); gaugeDataPointBuilder.value(Math.random()); counterBuilder.dataPoint(counterDataPointBuilder.build()); gaugeBuilder.dataPoint(gaugeDataPointBuilder.build()); } } Collection\u0026lt;MetricSnapshot\u0026gt; snaps = new ArrayList\u0026lt;MetricSnapshot\u0026gt;(); snaps.add(counterBuilder.build()); snaps.add(gaugeBuilder.build()); MetricSnapshots msnaps = new MetricSnapshots(snaps); return msnaps; } public List\u0026lt;String\u0026gt; getPrometheusNames() { List\u0026lt;String\u0026gt; names = new ArrayList\u0026lt;String\u0026gt;(); names.add(\u0026#34;x_calls_total\u0026#34;); names.add(\u0026#34;x_load\u0026#34;); return names; } } PrometheusScrapeRequest provides methods to access http-related infos from the request originally received by the endpoint\npublic interface PrometheusScrapeRequest { String getRequestURI(); String[] getParameterValues(String name); } Sample Prometheus scrape_config\n- job_name: \u0026#34;multi-target\u0026#34;\r# metrics_path defaults to \u0026#39;/metrics\u0026#39;\r# scheme defaults to \u0026#39;http\u0026#39;.\rparams:\rproc: [proc1, proc2]\rrelabel_configs:\r- source_labels: [__address__]\rtarget_label: __param_target\r- source_labels: [__param_target]\rtarget_label: instance\r- target_label: __address__\rreplacement: localhost:9401 static_configs:\r- targets: [\u0026#34;target1\u0026#34;, \u0026#34;target2\u0026#34;] It\u0026rsquo;s up to the specific MultiCollector implementation how to interpret the target parameter. It might be an explicit real target (i.e. via host name/ip address) or as an alias in some internal configuration. The latter is more suitable when the MultiCollector implementation is a proxy (see https://github.com/prometheus/snmp_exporter) In this case, invoking real target might require extra parameters (e.g. credentials) that might be complex to manage in Prometheus configuration (not considering the case where the proxy might become an \u0026ldquo;open relay\u0026rdquo;)\n","description":"This is for the upcoming release 1.1.0. To support multi-target pattern you can create a custom collector overriding the purposed internal method in ExtendedMultiCollector see SampleExtendedMultiCollector in io.prometheus.metrics.examples.httpserver\npublic class SampleExtendedMultiCollector extends ExtendedMultiCollector { public SampleExtendedMultiCollector() { super(); } @Override protected MetricSnapshots collectMetricSnapshots(PrometheusScrapeRequest scrapeRequest) { GaugeSnapshot.Builder gaugeBuilder = GaugeSnapshot.builder(); gaugeBuilder.name(\u0026#34;x_load\u0026#34;).help(\u0026#34;process load\u0026#34;); CounterSnapshot.Builder counterBuilder = CounterSnapshot.builder(); counterBuilder.name(PrometheusNaming.sanitizeMetricName(\u0026#34;x_calls_total\u0026#34;)).help(\u0026#34;invocations\u0026#34;); String[] targetNames = scrapeRequest.getParameterValues(\u0026#34;target\u0026#34;); String targetName; String[] procs = scrapeRequest.getParameterValues(\u0026#34;proc\u0026#34;); if (targetNames == null || targetNames."},{"id":26,"href":"/","title":"client_java","parent":"","content":"This is the documentation for the Prometheus Java client library version 1.0.0 and higher.\nThe main new features of the 1.0.0 release are:\nPrometheus native histograms: Support for the new Prometheus histogram type. OpenTelemetry Exporter: Push metrics in OTLP format to an OpenTelemetry endpoint. Runtime configuration: Configure metrics, exporters, and more at runtime using a properties file or system properties. Documentation and Examples\nIn addition to this documentation page we created an examples/ directory with end-to-end scenarios (Docker compose) illustrating new features.\nPerformance Benchmarks\nInitial performance benchmarks are looking great: All core metric types (including native histograms) allow concurrent updates, so if you instrument a performance critical Web service that utilizes all processor cores in parallel the metrics library will not introduce additional synchronization. See Javadoc comments in benchmarks/ for benchmark results.\nMore Info\nThe Grafana Labs Blog has a post Introducing the Prometheus Java Client 1.0.0 with a good overview of the release.\nThere will also be a presentation at the PromCon conference on 29 Sep 2023. Tune in to the live stream on https://promcon.io or watch the recording on YouTube.\nFor users of the 0.16.0 version and older\nUpdating to the 1.0.0 version is a breaking change. However, there\u0026rsquo;s a prometheus-metrics-simpleclient-bridge module available that allows you to use your existing simpleclient 0.16.0 metrics with the new 1.0.0 PrometheusRegistry. So you don\u0026rsquo;t need to upgrade your instrumentation code, you can keep using your existing metrics. See the compatibility \u0026gt; simpleclient in the menu on the left.\nThe pre 1.0.0 code is now maintained on the simpleclient feature branch.\nNot all simpleclient modules from 0.16.0 are included in the initial 1.0.0 release. Over the next couple of weeks we will work on porting the remaining modules, starting with pushgateway and the Servlet filter.\n","description":"This is the documentation for the Prometheus Java client library version 1.0.0 and higher.\nThe main new features of the 1.0.0 release are:\nPrometheus native histograms: Support for the new Prometheus histogram type. OpenTelemetry Exporter: Push metrics in OTLP format to an OpenTelemetry endpoint. Runtime configuration: Configure metrics, exporters, and more at runtime using a properties file or system properties. Documentation and Examples\nIn addition to this documentation page we created an examples/ directory with end-to-end scenarios (Docker compose) illustrating new features."},{"id":27,"href":"/tags/","title":"Tags","parent":"client_java","content":"","description":""}]